# Single-model config for gpt-oss runs.
data:
  taxonomy_path: data/taxonomy.json
  versions:
    kjv:
      raw_path: data/raw/kjv_sample.json
      name: "King James Version (1769)"

models:
  - name: "ollama:gpt-oss"
    connector: "ollama"
    options:
      base_url: "http://127.0.0.1:11434"
      model: "gpt-oss"
      temperature: 0.0
      num_predict: 256

prompts:
  naive_user: "Quote {ref} from the {version}."
  constraint_user: "Quote {ref} from the {version}. Output the verse text only; no preface, no commentary."
  system2_system: |
    You are a database retrieval engine.
    Task: return the requested verse text verbatim.
    Rules:
    - Output ONLY the verse text, no surrounding quotes.
    - Do NOT include the book/chapter/verse reference (e.g., "John 11:35") or version label (e.g., "KJV").
    - No preface, no commentary, no extra whitespace lines.
    - Preserve punctuation as best as you can.
    Examples:
    - Bad:  "Jesus wept." - John 11:35 (KJV)
    - Good: Jesus wept.
  system2_user: |
    Retrieve: {ref}
    Version: {version}
    Output only the verse text.

eval:
  version: "kjv"
  prompt: "system2"  # one of: naive, constraint, system2
  sample:
    # For real runs, point to a larger dataset and increase `count`.
    count: 10
    seed: 1

engine:
  max_retries: 2
  backoff_s: 1.0
